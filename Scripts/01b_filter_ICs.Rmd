---
title: Power spectra and overlaps
author: "Christian Coffman"
institute: University of Minnesota Twin Cities \newline
           Division of Biostatistics
date: |
      12/31/2020 \newline \newline \newline 
      ![](University_of_Minnesota.png){width=1.5in}
output:
  beamer_presentation:
    theme: "Antibes"
    slide_level: 3
    toc: true
    fonttheme: "structurebold"
bibliography: /home/christian/Documents/library.bib
csl: /home/christian/Documents/american-statistical-association.csl
header-includes: 
- \definecolor{Gold}{RGB}{255, 204, 51}
- \definecolor{Maroon1}{RGB}{112, 0, 25}
- \definecolor{Maroon2}{RGB}{92, 0, 15}
- \definecolor{Maroon3}{RGB}{92, 0, 15}
- \definecolor{Maroon4}{RGB}{82, 0, 10}
- \setbeamercolor{palette primary}{bg=Maroon1, fg = Gold}
- \setbeamercolor{palette secondary}{bg=Maroon2, fg = Gold}
- \setbeamercolor{palette tertiary}{bg=Maroon3, fg = Gold}
- \setbeamercolor{palette quaternary}{bg=Maroon4, fg = Gold}
- \setbeamercolor{palette sidebar secondary}{bg=Maroon1, fg = Gold}
- \setbeamercolor{palette sidebar secondary}{bg=Maroon2, fg = Gold}
- \setbeamercolor{palette sidebar tertiary}{bg=Maroon3, fg = Gold}
- \setbeamercolor{palette sidebar quaternary}{bg=Maroon4, fg = Gold}
- \setbeamercolor{item}{fg = Maroon1}
---

# high/low frequency ratio for IC's on a per subject basis.
```{r setup, include=FALSE, echo = FALSE, results = FALSE, comment = "", warning = FALSE}
knitr::opts_chunk$set(comment = NA, echo = FALSE, message = FALSE, results= 'hide', warning = FALSE)
source("01a_power_overlap_funcs.R")
options(fsl.path = '/usr/local/fsl')
options(fsl.outputtype = "NIFTI_GZ")

# list of files to investigate
ICfiles <- list.files("../SMs/", full.names = T)
```

```{r}
# name ICs based on max voxel
ICnames <- max_name_looper(ICfiles)
```


```{r}
atlas_file = '/home/christian/Research/Brain_stuff/Atlases/Yeo_17_2mm_mni152.nii.gz'

threshold <- 50
# Calculate the proportion of the IC contained within each given ROI
# loop around subjects at a time to avoid crashing
reftable <- read_delim(paste0("../thresh", threshold, '/overlapped_ICs.csv'), delim = ",")
IC_sizes <- read_delim(paste0("../thresh", threshold, '/IC_sizes.csv'), delim = ",") %>%
  mutate(IC= factor(IC))
print("Already put into Yeo \n Loading csv's...") 
```

```{r}

# Yeo_sizes <- as.data.frame(table(readNIfTI2(atlas_file)))%>%
#   dplyr::rename(ROI = Var1, ROI_size = Freq) %>%
#   mutate(ROI = factor(ROI)) %>%
#   filter(ROI %in% yeotable$ROI)


# stack all ICs and filter out ROI 0 (which cuts out real signal in the unlabeled region and nonsignal)
# total_tab <- reftable %>%
#   mutate(ROI = factor(ROI)) %>%
#   left_join(Yeo_sizes, by = "ROI") %>%
#   left_join(Yeo_dict, by = "ROI")
#   # pivot_longer(cols = c("ROI", "ROI_size"), names_to = "IC", values_to = "Overlap")
# total_tab$IC <- factor(sapply(strsplit(total_tab$IC,"_"), `[`, 2))


#  
# total_tab <-total_tab %>% 
#   left_join(IC_sizes, by = "IC") %>%
#   drop_na(ROI_size) %>%
#   filter(ROI != 0) %>%
#   mutate(prop_ROI = Overlap/ROI_size, prop_IC = Overlap / IC_size, DICE = Overlap /(ROI_size + IC_size)) 
```


# Measuring overlap of ICs with ROIs  
In order to label ICs using Yeo's ROIs we need to characterize two things:  
1. How well an IC could be described by a given ROI for interpretability. \textbf{Computation:}$$Pr(ROI|IC)=\frac{Pr(IC\cap ROI)}{Pr(IC)} $$.   

2. How well an ROI could be described by a given IC to make sure it's not a misnomer. \textbf{Computation:}$$Pr(IC|ROI) = \frac{P(IC\cap ROI)}{Pr(ROI)} $$.  


# IC description by ROI  
The # of pixels and the proportion of each IC(n=100) that lies within each Yeo ROI with and without including IC's with 0 overlap.
```{r IC-ROI overlap, fig.show="hold", out.width="49%",out.height="30%"}
total_tab %>%
  group_by(IC) %>% 
  filter(DICE == max(DICE, na.rm = TRUE)) %>%
  ggplot(aes(x= DICE)) +
  geom_histogram() +
  geom_vline(xintercept = 0.075)

total_tab %>%
  group_by(ROI) %>% 
  filter(DICE == max(DICE, na.rm = TRUE)) %>%
  ggplot(aes(x= DICE)) +
  geom_histogram() +
  geom_vline(xintercept = 0.075)


good_SMs <- total_tab %>%
  group_by(IC) %>% 
  filter(DICE == max(DICE, na.rm = TRUE), DICE > 0.075)
```



# ROI explanation by IC  
```{r ROI-IC overlap, fig.show="hold", out.width="49%",out.height="30%"}
total_tab %>%
  group_by(IC) %>%
  filter(DICE == max(DICE, na.rm = TRUE), DICE > 0.075) %>%
  ggplot(aes(x = prop_IC)) +
  geom_histogram() +
  xlab("Pr(IC|ROI)") +
  ggtitle("ROI explained by IC") +
  scale_x_log10()

```

```{r}
num_goodSMs<-dim(good_SMs)[1]


wide_ps <- all_powerspec %>% 
  # Filter only the ones with good enough SM's 
  filter(IC %in% paste0("V", good_SMs$IC)) %>%
  pivot_wider(id_cols = subject, names_from = IC, values_from = power) %>%
  unnest(-c(subject))
# grouped correlation function
func <- function(xx)
{
return(data.frame(COR = cor(xx)))
}

corrs <- ddply(wide_ps, .(subject), func) %>% dplyr::select(-c(subject, COR.subject))  %>% drop_na()


arr1 <- array(dim = c(num_goodSMs,num_goodSMs, 124))

for (k in 1:124) {
  for (j in 1:num_goodSMs) {
    arr1[,j, k] <- corrs[((k-1)*num_goodSMs+1):(k*num_goodSMs), j]
  } 
}

# look at the mean correlations across subjects
mean_corrs <- apply(arr1, c(1,2), mean, na.rm=T)
{hist(mean_corrs[mean_corrs !=1], main = "mean pairwise correlations", xlab = "Correlation")
lines(c(0.5,0.5), c(0,2400), col = "red", lwd = 4)}


max_corrs <- which(mean_corrs == max(mean_corrs[mean_corrs!=1]), arr.ind = TRUE)[1,]

all_powerspec$IC <- as.numeric(sub("." , "", all_powerspec$IC))
all_powerspec %>%
  filter(IC %in% max_corrs) %>%
  ggplot(aes(x=Hz, y = power)) +
  geom_point() +
  scale_x_log10() +
  facet_wrap(~IC)

arr1 <- array(dim = c(num_goodSMs,num_goodSMs, 124))

for (k in 1:124) {
  K <- str_pad(k, 3, pad = "0")
  arr1[,,k] <- as.data.frame(readNIfTI2(paste0("../GIG/timecourses/gica_cmd_sub", K, "_timecourses_ica_s1_.nii"))) %>%
  mutate(time = 1:907) %>%
  pivot_longer(-time, names_to = "IC", values_to = "Signal") %>%
  mutate(IC = sub(".","", IC)) %>%
  filter(IC %in% good_SMs$IC) %>%
  pivot_wider(names_from = IC, values_from = Signal) %>%
  dplyr::select(-time) %>%
  cor()
  print(K)
}

hist(arr1)

as.data.frame(apply(arr1, c(1,2), mean)) %>%
  pivot_longer(everything(), names_to = "IC", values_to = "Cor") %>%
  mutate(IC = sub(".", "", IC)) %>%
  ggplot(aes(x=Cor)) +
  geom_histogram(bins = 38) +
  geom_vline(xintercept = 0.36)

as.data.frame(apply(arr1, c(1,2), mean)) %>%
  pivot_longer(everything(), names_to = "IC", values_to = "Cor") %>%
  mutate(IC = sub(".", "", IC)) %>%
  filter(Cor < 0.36)

ps <- as.data.frame(apply(arr1, c(1,2), mean)) %>%
  pivot_longer(everything(), names_to = "IC", values_to = "Cor") %>%
  mutate(Cor = ifelse(Cor ==1, 0, Cor)) %>%
  group_by(IC) %>%
  dplyr::summarize(maxi = mean(Cor)) %>%
  mutate(t= (maxi*sqrt(126-2))/(1-maxi**2), p = 2*pt(t, df =124, lower.tail = FALSE))

ps$padj <- p.adjust(ps$p, method = "hochberg", n= 61)

# Select all IC's that weren't found to have significant correlations
IClowcorr <- ps[ps$padj > 0.05, ]$IC

# only one of the following that were correlated (since they weere correlated to one another)
include_one <- ps$padj %>% count() %>% 
  filter(freq >1, x <0.05) 

# include the first occurence of correlated IC's
included <- ps$IC[ps$padj %in% include_one$x][1]

IClowcorr <- append(IClowcorr, included)
IClowcorr <- factor(sub(".","", IClowcorr))
```

```{r}

goodSM_corr <- total_tab %>%
  filter(IC %in% IClowcorr)

highlow_long <- highlow_long %>%
  mutate(IC = factor(IC)) %>%
  filter(IC %in% IClowcorr)

# colors refer to IC's and density is direved from IC ratio across all subjects (n=155
ggplot(highlow_long, aes(x= ratio, group = IC, fill =factor(IC))) +
  geom_density(alpha = 0.2, size = 0.1) +
  theme(legend.position = "none")  +
  xlab("low/high ratio") +
  ggtitle("All high/low ratios for all subjects/IC pairs at high/low cutoff = 0.1Hz") +
  geom_vline(xintercept = 10) +
  scale_x_log10()
```

```{r}

# IC_times %>%
#   mutate(ave = (V27+V28+V29)/3, sd = sqrt((ave-V27)^2 + (ave-V28)^2 + (ave-V29)^2) )%>%
#   ggplot(aes(x = 1:912, y= ave, ymin= ave - sd, ymax= ave + sd)) +
#   geom_ribbon(alpha= 0.5) +
#   ylim(-1.5,1.5)


# IC_times %>%
#   mutate(time = 1:912) %>%
#   pivot_longer(cols = -time, names_to = "IC") %>%
#   filter(IC %in% c("V27", "V28", "V29")) %>%
#   ggplot(aes(x = time, y= value, col = IC)) +
#   geom_line(alpha =0.5) +
#   ylim(-1.5,1.5) +
#   xlim(400,500)

IC_powerspec <- IC_times %>%
  mutate(time = 1:907) %>%
  pivot_longer(cols = -time, names_to = "IC", values_to = "Signal") %>%
  filter(IC %in% c("V4", "V12", "V26")) %>%
  nest(data=-IC) %>%
  mutate(powerspec = map(data, ~ fft(.$Signal, inverse = FALSE))) %>%
  unnest(powerspec) %>%
  mutate(fre = powerspec - 1/(907*(1/1)),
         sqr_mod = abs(fre) **2,
         power = sqr_mod /(907 * (1/1)),
         Hz = rep(linspace(0, 1/ (2 * 1), 907), 3)) %>%
  filter(Hz < max(Hz)/2)

IC_powerspec %>%
  ggplot(aes(x= Hz, y = power, col = IC)) +
  geom_line()


```


There seems to be a good cutoff point at $10$      

# Summary of labelings  
with a cutoff of $10$ from the previous graph, we'd keep $\approx 1/3$ and discard $\approx 2/3$ of all subject level IC's based off of frequency alone.  
The ratio of IC's kept per subject and per IC was stable at around the same percentage.  

```{r include = TRUE, echo = FALSE, results = FALSE, out.width="60%",out.height="60%"} 
cutoff <- 10
ICkeeprat <- highlow_long %>%
  drop_na() %>%
  mutate(Signal = ratio > cutoff, Noise = !Signal) %>%
  dplyr::group_by(IC) %>%
  dplyr::summarise(prop_sig = sum(Signal)/length(timecourse.files), prop_noise = sum(Noise)/length(timecourse.files))
```

## The filter works very well at a subject level, however, we need to use group level filters. So in order to include the information from the subject level i calculated the number of subjects for which a time course from a specific IC was kept.

```{r} 
ICkeeprat %>%
  ggplot(aes(x= prop_sig)) +
  geom_histogram() +
  xlab('proportion of subects above thresholds per IC') +
  ggtitle('Proportion of subject level ICs above threshold') +
  geom_vline(xintercept = 0.5)

# highlow_long %>% filter(Subject %in% c('subj33', 'subj47', 'subj122'), IC %in% c(62,36,56,4,10,65,32,39,76)) %>% arrange(Subject)
kept <- ICkeeprat[ICkeeprat$prop_sig > 0.5,]$IC
```



```{r  fig.show="hold", out.width="49%",out.height="30%"}
ave_highlow <- highlow_long %>%
  group_by(IC, Subject) %>%
  dplyr::summarize(ave = mean(ratio, na.rm = TRUE)) %>%
  mutate(IC = factor(IC))
```
    
Log transform creates a little separation, but still no obvious cutoff point, so $e^{-1.6}$ was chosen




# Here I'll actually choose the IC's
```{r} 

filtered_ICs <- data.frame(IC = 1:100)

filtered_ICs <- filtered_ICs %>%
  filter(IC %in% goodSM_corr$IC, IC %in% kept)


best_cover <- total_tab %>%
  filter(IC %in% filtered_ICs$IC) %>%
  drop_na(prop_IC) %>%
  group_by(IC) %>% 
  dplyr::summarize(best_coverage = max(prop_IC))

dFNC_labels <- total_tab %>%
  dplyr::select(ROI, IC, prop_IC) %>%
  filter(prop_IC %in% best_cover$best_coverage) %>%
  mutate(ROI = factor(ROI)) %>%
  left_join(yeotable, by = "ROI")

dFNC_labels %>%
  dplyr::select(IC, Name) %>%
  arrange(Name) %>%
  write_csv("../thresh50/dFNC_labels.csv")

read_csv("../thresh50/dFNC_labels.csv")

```

# IC timecourses for Hidden Markov models
```{r}
kept_ICs <- sort(dFNC_labels$IC)
tcs <- data.frame(matrix(ncol =102))
colnames(tcs) <- c("Subject", "time", 1:100)
for (k in 1:126) {
  K <- str_pad(k, 3, pad = "0")
  info <- data.frame("Subject" = k, "time" = 1:912)
  temp.tcs <- cbind(info, readNIfTI2(paste0("timecourses/gica_cmd_sub", K, "_timecourses_ica_s1_.nii")))
  tcs <- rbind(tcs, temp.tcs) 
    
}

tcs <- tcs %>%
  pivot_longer(-c(Subject, time), names_to = "IC", values_to = "Signal") %>%
  filter(!is.na(time), IC %in% kept_ICs) %>%
  arrange(Subject, IC)

subjects <- read_delim("files.txt", delim = "\n", col_names = FALSE)

subjects <- str_split(subjects$X1, "/", simplify = TRUE)[,6]
subjects <- as.numeric(sub("sub-", "", subjects))

subjects <- subjects[tcs$Subject]

tcs <- tcs %>%
  mutate(grid = subjects)

tcs <- tcs %>%
  dplyr::select(-Subject)

write.csv(tcs, "Filtered_IC_tcs.csv")
```